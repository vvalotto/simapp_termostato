# Skill: implement-us

**Nombre del comando:** `/implement-us`

**DescripciÃ³n:** Implementador asistido de Historias de Usuario siguiendo arquitectura MVC + Factory/Coordinator

---

## PropÃ³sito

Este skill guÃ­a paso a paso la implementaciÃ³n de una Historia de Usuario (US) del proyecto ISSE_Simuladores, asegurando:
- Adherencia a la arquitectura de referencia (ADR-003)
- GeneraciÃ³n de escenarios BDD
- ImplementaciÃ³n MVC completa
- Tests unitarios y de integraciÃ³n
- ValidaciÃ³n de quality gates

---

## Uso

```bash
/implement-us US-001
/implement-us US-001 --producto ux_termostato
/implement-us US-001 --skip-bdd  # Salta generaciÃ³n BDD
```

---

## Proceso del Skill

### Fase 0: ValidaciÃ³n de Contexto

1. **Verificar que existe la historia de usuario**
   - Buscar en `{producto}/docs/HISTORIAS-USUARIO-*.md`
   - Extraer: tÃ­tulo, criterios de aceptaciÃ³n, puntos, prioridad

2. **Validar arquitectura de referencia**
   - Confirmar que existe ADR-003 o arquitectura.md
   - Verificar patrones: MVC, Factory, Coordinator

3. **Verificar estÃ¡ndares de calidad**
   - Confirmar CLAUDE.md con quality gates
   - Confirmar estructura de tests (conftest.py)

**Output Fase 0:** Resumen de contexto validado

---

### Fase 1: GeneraciÃ³n de Escenarios BDD

**AcciÃ³n:** Analizar la US y generar escenarios BDD en formato Gherkin

**Template:** `.claude/templates/bdd-scenario.feature`

**Pasos:**
1. Leer criterios de aceptaciÃ³n de la US
2. Por cada criterio, generar un escenario BDD:
   - Given (contexto/precondiciÃ³n)
   - When (acciÃ³n del usuario)
   - Then (resultado esperado)
3. Generar archivo: `{producto}/tests/features/US-XXX-{nombre}.feature`

**Ejemplo Output:**
```gherkin
Feature: Ver temperatura ambiente actual (US-001)

  Scenario: Display muestra temperatura cuando hay conexiÃ³n
    Given el termostato estÃ¡ encendido
    And hay conexiÃ³n con el Raspberry Pi
    When se recibe temperatura de 22.5Â°C
    Then el display muestra "22.5"
    And el label muestra "Temperatura Ambiente"
```

**Punto de aprobaciÃ³n:** Usuario revisa y aprueba escenarios BDD

---

### Fase 2: GeneraciÃ³n del Plan de ImplementaciÃ³n

**AcciÃ³n:** Crear plan detallado basado en arquitectura MVC

**Template:** `.claude/templates/implementation-plan.md`

**Pasos:**
1. Identificar componentes a crear segÃºn arquitectura:
   - Si es panel UI â†’ Modelo + Vista + Controlador
   - Si es comunicaciÃ³n â†’ Cliente o Servidor
   - Si es dominio â†’ Dataclass + lÃ³gica
2. Identificar dependencias (Factory, Coordinator)
3. Generar checklist de tareas
4. Estimar tiempo por tarea

**Ejemplo Output:**
```markdown
# Plan de ImplementaciÃ³n: US-001 - Ver temperatura ambiente

## Componentes a Implementar

### 1. Panel Display (MVC)
- [ ] app/presentacion/paneles/display/modelo.py (10 min)
- [ ] app/presentacion/paneles/display/vista.py (20 min)
- [ ] app/presentacion/paneles/display/controlador.py (15 min)

### 2. IntegraciÃ³n con ComunicaciÃ³n
- [ ] Conectar ServidorEstado â†’ DisplayControlador (10 min)

### 3. Tests
- [ ] tests/test_display_modelo.py (15 min)
- [ ] tests/test_display_vista.py (20 min)
- [ ] tests/test_display_controlador.py (20 min)
- [ ] tests/test_display_integracion.py (15 min)

### 4. ValidaciÃ³n
- [ ] Ejecutar escenarios BDD (5 min)
- [ ] Quality gates (Pylint, CC, MI) (5 min)

**Total estimado:** 2h 15min
**Estado:** 0/12 tareas completadas
```

**Archivo generado:** `{producto}/docs/plans/US-XXX-plan.md`

**Punto de aprobaciÃ³n:** Usuario revisa y aprueba el plan

---

### Fase 3: ImplementaciÃ³n Guiada por Tareas

**AcciÃ³n:** Por cada tarea del plan, guiar la implementaciÃ³n

**Pasos:**
1. **Seleccionar prÃ³xima tarea** del plan (primera no completada)
2. **Mostrar contexto:**
   - QuÃ© se va a implementar
   - PatrÃ³n arquitectÃ³nico a seguir
   - Ejemplo de cÃ³digo similar existente
3. **Generar cÃ³digo base** usando templates
4. **Presentar cÃ³digo** para revisiÃ³n del usuario
5. **Escribir archivo** si usuario aprueba
6. **Ejecutar tests** de la tarea si corresponde
7. **Actualizar plan INMEDIATAMENTE** despuÃ©s de completar la tarea:
   - Marcar checkbox `- [x]` de la tarea completada en el plan
   - Actualizar contador "Tareas completadas: X/Y"
   - Actualizar porcentaje de progreso
8. **Continuar** con siguiente tarea

**IMPORTANTE:** El plan debe actualizarse **despuÃ©s de cada tarea completada**, no al final de todas las tareas. Esto da visibilidad en tiempo real del progreso.

**Ejemplo de GuÃ­a para Tarea:**
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ TAREA 1/12: Implementar DisplayModelo
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ UbicaciÃ³n: app/presentacion/paneles/display/modelo.py

ğŸ“ PatrÃ³n: Modelo MVC (dataclass inmutable)

ğŸ’¡ Referencia: Revisar PanelEstadoModelo en simulador_bateria

âœï¸  CÃ³digo propuesto:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[CÃ³digo generado aquÃ­]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â“ Â¿Aprobar e implementar? (yes/no/edit)
```

**Punto de aprobaciÃ³n:** Usuario aprueba cada tarea antes de continuar

---

### Fase 4: Tests Unitarios

**AcciÃ³n:** Por cada componente, implementar tests

**Template:** `.claude/templates/test-unit.py`

**Pasos:**
1. Identificar quÃ© testear segÃºn tipo de componente:
   - Modelo: validaciÃ³n de datos, inmutabilidad
   - Vista: renderizado, actualizaciÃ³n
   - Controlador: seÃ±ales, lÃ³gica de negocio
2. Generar tests usando fixtures de conftest.py
3. Ejecutar tests: `pytest tests/test_XXX.py -v`
4. Validar coverage: `pytest --cov=app/presentacion/paneles/display --cov-report=term`

**Ejemplo Output:**
```python
# tests/test_display_modelo.py
import pytest
from app.presentacion.paneles.display.modelo import DisplayModelo

class TestCreacion:
    """Tests de creaciÃ³n del modelo."""

    def test_crear_con_valores_default(self):
        modelo = DisplayModelo()
        assert modelo.temperatura == 0.0
        assert modelo.encendido is True

    def test_es_inmutable(self):
        modelo = DisplayModelo(temperatura=22.5)
        with pytest.raises(AttributeError):
            modelo.temperatura = 23.0
```

**Objetivo:** Coverage > 95% del nuevo cÃ³digo

---

### Fase 5: Tests de IntegraciÃ³n

**AcciÃ³n:** Validar que componentes funcionan juntos

**Pasos:**
1. Crear test que simula flujo completo:
   - ServidorEstado recibe JSON
   - JSON se parsea a EstadoTermostato
   - SeÃ±al se emite a DisplayControlador
   - DisplayControlador actualiza modelo
   - Vista se renderiza
2. Usar mocks de PyQt (pytest-qt)
3. Ejecutar: `pytest tests/test_display_integracion.py -v`

**Ejemplo Output:**
```python
def test_display_actualiza_desde_servidor(qapp, qtbot):
    """Test end-to-end: servidor â†’ controlador â†’ vista."""
    # Setup
    servidor = ServidorEstado(puerto=14001)
    controlador = crear_display_controlador()

    # Conectar
    servidor.estado_recibido.connect(
        controlador.actualizar_desde_estado
    )

    # Simular recepciÃ³n de JSON
    json_data = '{"temp_actual": 22.5, ...}'
    servidor._on_data_received(json_data)

    # Validar
    assert controlador.modelo.temperatura == 22.5
    assert "22.5" in controlador.vista.label_temp.text()
```

---

### Fase 6: ValidaciÃ³n BDD

**AcciÃ³n:** Ejecutar escenarios BDD generados en Fase 1

**Pasos:**
1. Configurar pytest-bdd si no existe
2. Implementar steps de los escenarios:
   - Given steps (setup de contexto)
   - When steps (acciones)
   - Then steps (aserciones)
3. Ejecutar: `pytest tests/features/US-XXX-*.feature -v`
4. Validar que TODOS los escenarios pasan

**Ejemplo Output:**
```
tests/features/US-001-ver-temperatura.feature::Display muestra temperatura PASSED
tests/features/US-001-ver-temperatura.feature::Display sin conexiÃ³n PASSED
tests/features/US-001-ver-temperatura.feature::ActualizaciÃ³n tiempo real PASSED

3 scenarios passed, 0 failed
```

---

### Fase 7: Quality Gates

**AcciÃ³n:** Validar mÃ©tricas de calidad del cÃ³digo

**Pasos:**
1. **Ejecutar Pylint:**
   ```bash
   cd {producto}
   pylint app/presentacion/paneles/display/
   ```
   - **Target:** â‰¥ 8.0

2. **Calcular MÃ©tricas:**
   ```bash
   python quality/scripts/calculate_metrics.py app/presentacion/paneles/display
   ```
   - **CC promedio:** â‰¤ 10
   - **MI promedio:** > 20

3. **Validar Coverage:**
   ```bash
   pytest tests/test_display_* --cov=app/presentacion/paneles/display --cov-report=term --cov-report=json
   ```
   - **Target:** â‰¥ 95%
   - **Nota:** Se genera reporte en terminal y JSON (no HTML)

4. **Generar Reporte:**
   - Archivo: `{producto}/quality/reports/US-XXX-quality.json`

**Ejemplo Output:**
```json
{
  "us_id": "US-001",
  "fecha": "2026-01-16T15:30:00",
  "metricas": {
    "pylint": 9.2,
    "cc_promedio": 2.1,
    "mi_promedio": 78.5,
    "coverage": 97.3
  },
  "estado": "APROBADO",
  "observaciones": []
}
```

**Criterio de Ã©xito:** Todas las mÃ©tricas superan los umbrales

---

### Fase 8: ActualizaciÃ³n de DocumentaciÃ³n

**AcciÃ³n:** Actualizar documentos relevantes

**Pasos:**
1. **Actualizar plan de implementaciÃ³n:**
   - Marcar US como "Completada"
   - Agregar tiempo real vs estimado
   - Notas de lecciones aprendidas

2. **Actualizar arquitectura (si aplica):**
   - Si se agregÃ³ panel nuevo, documentar en arquitectura.md
   - Actualizar diagramas si corresponde

3. **Actualizar CHANGELOG.md:**
   - Agregar entrada con US implementada
   - Formato: `[US-001] Ver temperatura ambiente - Display LCD implementado`

4. **Actualizar README (si aplica):**
   - Si se agregÃ³ funcionalidad visible, actualizar screenshots/descripciÃ³n

---

### Fase 9: Reporte Final

**AcciÃ³n:** Generar reporte de implementaciÃ³n

**Template:** `.claude/templates/implementation-report.md`

**Contenido:**
```markdown
# Reporte de ImplementaciÃ³n: US-001

## Resumen
- **Historia:** US-001 - Ver temperatura ambiente
- **Puntos estimados:** 3
- **Tiempo real:** 2h 10min
- **Estado:** âœ… COMPLETADO

## Componentes Implementados
- âœ… DisplayModelo (modelo.py)
- âœ… DisplayVista (vista.py)
- âœ… DisplayControlador (controlador.py)
- âœ… Tests unitarios (12 tests)
- âœ… Tests integraciÃ³n (3 tests)
- âœ… Escenarios BDD (3 escenarios)

## MÃ©tricas de Calidad
- Pylint: 9.2/10 âœ…
- CC: 2.1 (target â‰¤10) âœ…
- MI: 78.5 (target >20) âœ…
- Coverage: 97.3% (target â‰¥95%) âœ…

## Archivos Creados
- app/presentacion/paneles/display/modelo.py
- app/presentacion/paneles/display/vista.py
- app/presentacion/paneles/display/controlador.py
- tests/test_display_modelo.py
- tests/test_display_vista.py
- tests/test_display_controlador.py
- tests/test_display_integracion.py
- tests/features/US-001-ver-temperatura.feature
- docs/plans/US-001-plan.md
- quality/reports/US-001-quality.json

## Criterios de AceptaciÃ³n
- [x] Display muestra temperatura con formato X.X Â°C
- [x] Temperatura se actualiza automÃ¡ticamente
- [x] Fuente grande y clara (48px+)
- [x] Fondo LCD verde oscuro
- [x] Label indica "Temperatura Ambiente"
- [x] Muestra "---" sin conexiÃ³n

## PrÃ³ximos Pasos
- [ ] Implementar US-002 (Estado climatizador)
- [ ] Integrar DisplayControlador en Factory
- [ ] Conectar en Coordinator con ServidorEstado
```

**Archivo:** `{producto}/docs/reports/US-XXX-report.md`

---

## ConfiguraciÃ³n del Skill

### Variables de Entorno (opcionales)

```bash
# .env o .claude/config
IMPLEMENTADOR_AUTO_COMMIT=false  # Git commit automÃ¡tico por fase
IMPLEMENTADOR_AUTO_TEST=true     # Ejecutar tests automÃ¡ticamente
IMPLEMENTADOR_VERBOSE=true       # Logs detallados
```

### Archivos de ConfiguraciÃ³n

**`.claude/skills/implement-us-config.json`**
```json
{
  "templates_dir": ".claude/templates",
  "plans_dir": "docs/plans",
  "reports_dir": "docs/reports",
  "quality_gates": {
    "pylint_min": 8.0,
    "cc_max": 10,
    "mi_min": 20,
    "coverage_min": 95
  },
  "checkpoint_approval": true,
  "auto_run_tests": true,
  "generate_bdd": true
}
```

---

## Dependencias

- Python 3.12+
- pytest
- pytest-qt
- pytest-bdd (opcional, para BDD)
- pytest-cov
- pylint
- radon

---

## Estructura de Archivos Generados

```
{producto}/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ features/               # Escenarios BDD
â”‚   â”‚   â””â”€â”€ US-XXX-*.feature
â”‚   â”œâ”€â”€ test_XXX_modelo.py      # Tests unitarios
â”‚   â”œâ”€â”€ test_XXX_vista.py
â”‚   â”œâ”€â”€ test_XXX_controlador.py
â”‚   â””â”€â”€ test_XXX_integracion.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ plans/
â”‚   â”‚   â””â”€â”€ US-XXX-plan.md      # Plan de implementaciÃ³n
â”‚   â””â”€â”€ reports/
â”‚       â””â”€â”€ US-XXX-report.md    # Reporte final
â””â”€â”€ quality/reports/
    â””â”€â”€ US-XXX-quality.json     # MÃ©tricas de calidad
```

---

## Ejemplo de Uso Completo

```
User: /implement-us US-001

Claude:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ Implementador de Historia de Usuario
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ Historia: US-001 - Ver temperatura ambiente
ğŸ“¦ Producto: ux_termostato
â­ Prioridad: Alta
ğŸ¯ Puntos: 3

â”â”â” Fase 0: ValidaciÃ³n de Contexto â”â”â”

âœ… Historia encontrada en docs/HISTORIAS-USUARIO-UX-TERMOSTATO.md
âœ… Arquitectura de referencia: ADR-003
âœ… EstÃ¡ndares: CLAUDE.md
âœ… Tests configurados: conftest.py

â”â”â” Fase 1: GeneraciÃ³n de Escenarios BDD â”â”â”

Generando escenarios basados en criterios de aceptaciÃ³n...

[Muestra escenarios generados]

Â¿Aprobar escenarios BDD? (yes/no/edit)

User: yes

Claude:
âœ… Escenarios guardados en tests/features/US-001-ver-temperatura.feature

â”â”â” Fase 2: Plan de ImplementaciÃ³n â”â”â”

[Muestra plan detallado]

Â¿Aprobar plan? (yes/no/edit)

User: yes

â”â”â” Fase 3: ImplementaciÃ³n Tarea 1/12 â”â”â”

ğŸ“‹ Implementar DisplayModelo

[Muestra cÃ³digo propuesto]

Â¿Implementar? (yes/no/edit)

User: yes

âœ… Archivo creado: app/presentacion/paneles/display/modelo.py
â­ï¸  Siguiente tarea: Implementar DisplayVista...
```

---

## Notas de ImplementaciÃ³n

### Puntos de ExtensiÃ³n

El skill puede extenderse para:
- IntegraciÃ³n con Jira (actualizar estado de US)
- Git automation (crear branch, commits por tarea)
- Notificaciones (Slack, email al completar)
- Dashboard web de progreso
- AnÃ¡lisis de velocity (puntos/dÃ­a)

### Limitaciones

- No reemplaza revisiÃ³n de cÃ³digo humana
- Patrones arquitectÃ³nicos deben estar bien definidos
- Requiere historias de usuario bien escritas
- Tests BDD requieren pytest-bdd configurado

---

## Mantenimiento

### Actualizar Templates

Los templates estÃ¡n en `.claude/templates/` y pueden editarse:
- `bdd-scenario.feature` - Template de escenarios Gherkin
- `implementation-plan.md` - Template de plan
- `test-unit.py` - Template de test unitario
- `implementation-report.md` - Template de reporte

### Logs

El skill genera logs en `.claude/logs/implement-us-{timestamp}.log`

---

## VersiÃ³n

**VersiÃ³n:** 1.0
**Fecha:** 2026-01-16
**Autor:** Victor Valotto
**Proyecto:** ISSE_Simuladores
